<!DOCTYPE HTML>

<html>
<head>
<meta charset="UTF-8">
<title>Chekhov's Gun</title>
<meta name="robots" content="index,follow">
<meta name="googlebot" content="index,follow">
<meta name="Keywords" content="William Wiebe, Will Wiebe, art, tech, predictive policing, acoustic surveillance, ShotSpotter">

<link rel="stylesheet" href="ww.css">
</head>

<body>
<p><strong>Chekhov's Gun</strong><br>
2018<br>
</p>
<p>
<em>Chekhov’s Gun</em> mobilizes the variances between human and machine acoustic perception in order to examine the creation, funding, and development of the gunshot detection system ShotSpotter.
</p>
<p>
Using a network of microphones dispersed throughout a city, ShotSpotter triangulates the location of a gunshot by comparing the distance from its point of origin to the three closest microphones. ShotSpotter installs and maintains these systems themselves, renting access to local police departments. Besides real-time surveillance, the proprietary data which ShotSpotter collects is fed into the company’s machine learning dataset and spun off into predictive policing programs which police departments may also subscribe to. Oftentimes, the data must be retrofit by human analysts to substantiate the claims made by police officers in court.
</p>
<p>
    After speaking with the individuals that developed the technology and pioneered its use in predictive policing suites, Wiebe met with a group of technical support engineers who are employed by ShotSpotter to visually confirm that the soundwaves selected by ShotSpotter’s algorithm are gunfire and that the time signatures have been correctly synced for echolocation. In <em>Three Sisters</em>, the employees rehearse the staging of the final duel in <em>The Good, the Bad, and the Ugly</em> beneath a voiceover that reads excerpts of court transcripts in which ShotSpotter employees testify testimony to the efficacy of the system in order to prove its admissibility to the court. The staging of the three employees anticipates the triangulation of gunfire, while the displaced audio explores the failed attempt to remove human biases from automated systems. Other works explore the use and interpretation of sound as evidence, including an acoustic diffuser produced from a Chicago homicide prediction map (<em>Diffusion Drawing #1</em>); a group of screenprints recording mishearings in ShotSpotter employee testimony (<em>sounds like trouble i-iii</em>); and a group of embossings of gunfire waveforms recorded by ShotSpotter for their machine learning database, here encoded for compact disc, the technological standard for courtroom evidence (<em>sounds like trouble iv-vi</em>).
</p>
<p>
A series of acoustic interventions used a purpose-built parametric speaker to disrupt the ShotSpotter system and communicate with these employees, isolating an individual microphone in Chicago from its intended function in the network (<em>Product Demonstration</em>).
</p>
<br>
<p><img src="CG-1.jpg" height="675"></p>
<p><img src="CG-2.jpg" width="900"></p>
<p><img src="CG-cover.jpg" width="900"></p>
<p><img src="CG-3.jpg" height="600"> <img src="CG-4.jpg" height="600"> <img src="CG-5.jpg" height="600"></p>
<p><img src="CG-6.jpg" height="675"> <img src="CG-7.jpg" height="675"> <img src="CG-8.jpg" height="675"></p>
<p><img src="CG-9.jpg" width="900"></p>
<p><img src="CG-10.jpg" width="900"></p>
<p><img src="CG-11.jpg" width="900"></p>
<p><img src="CG-12.jpg" width="900"></p>
<p><img src="CG-13.jpg" width="900"></p>
</body>
</html>